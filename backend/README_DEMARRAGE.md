# ğŸš€ Guide de dÃ©marrage des serveurs

## Architecture du projet

Le projet nÃ©cessite **2 serveurs** pour fonctionner correctement :

1. **Serveur Flask (Llama)** - Port **8000** : GÃ¨re l'IA conversationnelle
2. **Serveur Django** - Port **8001** : GÃ¨re l'API principale et le scraping

---

## ğŸ¯ DÃ©marrage rapide

### Option 1 : Scripts automatiques (RecommandÃ©)

#### Windows :

1. **Terminal 1** - Serveur Llama :

   ```bash
   cd backend
   start_llama.bat
   ```

2. **Terminal 2** - Serveur Django :
   ```bash
   cd backend
   start_django.bat
   ```

---

### Option 2 : Commandes manuelles

#### Terminal 1 - Serveur Flask (Llama) :

```bash
cd backend
venv\Scripts\activate
python llama_server.py
```

âœ… Devrait afficher : `Serveur Llama demarre sur http://0.0.0.0:8000`

#### Terminal 2 - Serveur Django :

```bash
cd backend
venv\Scripts\activate
python manage.py runserver 8001
```

âœ… Devrait afficher : `Starting development server at http://127.0.0.1:8001/`

---

## âœ… VÃ©rification

Une fois les deux serveurs dÃ©marrÃ©s, testez :

1. **Serveur Llama** : http://127.0.0.1:8000/health
   - Doit retourner : `{"status": "OK"}`

2. **Serveur Django** : http://127.0.0.1:8001/api/health/
   - Doit retourner un JSON avec les informations du serveur

3. **Frontend** : Assurez-vous que le frontend React est dÃ©marrÃ© sur le port 5173

---

## âŒ DÃ©pannage

### "Le serveur Django ne rÃ©pond pas"

**Causes possibles :**

1. Le serveur Django n'est pas dÃ©marrÃ©
   - Solution : ExÃ©cutez `start_django.bat` ou `python manage.py runserver 8001`

2. Le serveur tourne sur un autre port
   - VÃ©rifiez les processus : `netstat -ano | findstr :8001`

3. Erreur de configuration
   - ExÃ©cutez : `python manage.py check`

### "Erreur CORS"

Si vous voyez des erreurs CORS dans la console :

- VÃ©rifiez que `corsheaders` est dans `INSTALLED_APPS` dans `settings.py`
- VÃ©rifiez que votre origine frontend (http://localhost:5173 ou http://127.0.0.1:5173) est dans `CORS_ALLOWED_ORIGINS`

### Le serveur Llama ne rÃ©pond pas

1. VÃ©rifiez que le modÃ¨le Llama est prÃ©sent dans `venv/GPT4AllModels/`
2. VÃ©rifiez que Flask dÃ©marre sans erreur
3. Testez : `curl http://127.0.0.1:8000/health`

---

## ğŸ“ Notes importantes

- Les deux serveurs doivent tourner **en mÃªme temps**
- Ne fermez pas les fenÃªtres de terminal pendant l'utilisation
- Le frontend communique avec Django sur le port **8001**
- Django communique avec Llama sur le port **8000**

---

## ğŸ”§ Commandes utiles

```bash
# VÃ©rifier les ports utilisÃ©s
netstat -ano | findstr :8000
netstat -ano | findstr :8001

# ArrÃªter un processus sur un port (remplacez PID par le numÃ©ro du processus)
taskkill /PID <PID> /F

# VÃ©rifier la configuration Django
python manage.py check

# CrÃ©er les migrations (si nÃ©cessaire)
python manage.py makemigrations
python manage.py migrate
```

---

## ğŸ‰ PrÃªt !

Une fois les deux serveurs dÃ©marrÃ©s et vÃ©rifiÃ©s, vous pouvez utiliser le chatbot dans votre application frontend !
